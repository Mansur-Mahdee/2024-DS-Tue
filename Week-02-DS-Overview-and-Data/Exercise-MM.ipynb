{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall 2024 Data Science Track: Week 2 - Data Cleaning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages, Packages, Packages!\n",
    "\n",
    "Import *all* the things here! You need the standard stuff: `pandas` and `numpy`.\n",
    "\n",
    "If you got more stuff you want to use, add them here too. ðŸ™‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "With the packages out of the way, now you will be working with the following data sets:\n",
    "\n",
    "* `food_coded.csv`: [Food choices](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) from Kaggle\n",
    "* `Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`: [Ask A Manager Salary Survey 2021 (Responses)](https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/view?&gid=1625408792) as *Tab Separated Values (.tsv)* from Google Docs\n",
    "\n",
    "Each one poses different challenges. But youâ€™llâ€•of courseâ€•overcome them with what you learned in class! ðŸ˜‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food Choices Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>we dont have comfort</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>345</td>\n",
       "      <td>car racing</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza, Mac and cheese, ice cream</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>Not sure, 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Candy, brownies and soda.</td>\n",
       "      <td>None, i don't eat comfort food. I just eat whe...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>345</td>\n",
       "      <td>None.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chocolate, ice cream, french fries, pretzels</td>\n",
       "      <td>stress, boredom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>690</td>\n",
       "      <td>soccer</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ice cream, cheeseburgers, chips.</td>\n",
       "      <td>I eat comfort food when im stressed out from s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>725.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Donuts, ice cream, chips</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>725.0</td>\n",
       "      <td>345</td>\n",
       "      <td>none</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mac and cheese, chocolate, and pasta</td>\n",
       "      <td>Stress, anger and sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>580.0</td>\n",
       "      <td>345</td>\n",
       "      <td>field hockey</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "0    2.4       2          1               430           NaN           315.0   \n",
       "1  3.654       1          1               610           3.0           420.0   \n",
       "2    3.3       1          1               720           4.0           420.0   \n",
       "3    3.2       1          1               430           3.0           420.0   \n",
       "4    3.5       1          1               720           2.0           420.0   \n",
       "5   2.25       1          1               610           3.0           980.0   \n",
       "6    3.8       2          1               610           3.0           420.0   \n",
       "7    3.3       1          1               720           3.0           420.0   \n",
       "8    3.3       1          1               430           NaN           420.0   \n",
       "9    3.3       1          1               430           3.0           315.0   \n",
       "\n",
       "   coffee                                  comfort_food  \\\n",
       "0       1                                          none   \n",
       "1       2                   chocolate, chips, ice cream   \n",
       "2       2               frozen yogurt, pizza, fast food   \n",
       "3       2              Pizza, Mac and cheese, ice cream   \n",
       "4       2                  Ice cream, chocolate, chips    \n",
       "5       2                     Candy, brownies and soda.   \n",
       "6       2  Chocolate, ice cream, french fries, pretzels   \n",
       "7       1              Ice cream, cheeseburgers, chips.   \n",
       "8       1                      Donuts, ice cream, chips   \n",
       "9       2         Mac and cheese, chocolate, and pasta    \n",
       "\n",
       "                                comfort_food_reasons  \\\n",
       "0                              we dont have comfort    \n",
       "1                               Stress, bored, anger   \n",
       "2                                    stress, sadness   \n",
       "3                                            Boredom   \n",
       "4                         Stress, boredom, cravings    \n",
       "5  None, i don't eat comfort food. I just eat whe...   \n",
       "6                                    stress, boredom   \n",
       "7  I eat comfort food when im stressed out from s...   \n",
       "8                                           Boredom    \n",
       "9                         Stress, anger and sadness    \n",
       "\n",
       "   comfort_food_reasons_coded  ...  soup  sports  thai_food tortilla_calories  \\\n",
       "0                         9.0  ...   1.0     1.0          1            1165.0   \n",
       "1                         1.0  ...   1.0     1.0          2             725.0   \n",
       "2                         1.0  ...   1.0     2.0          5            1165.0   \n",
       "3                         2.0  ...   1.0     2.0          5             725.0   \n",
       "4                         1.0  ...   1.0     1.0          4             940.0   \n",
       "5                         4.0  ...   1.0     2.0          4             940.0   \n",
       "6                         1.0  ...   1.0     1.0          5             940.0   \n",
       "7                         1.0  ...   1.0     2.0          1             725.0   \n",
       "8                         2.0  ...   2.0     2.0          5             725.0   \n",
       "9                         1.0  ...   1.0     1.0          4             580.0   \n",
       "\n",
       "   turkey_calories   type_sports veggies_day  vitamins  waffle_calories  \\\n",
       "0              345    car racing           5         1             1315   \n",
       "1              690   Basketball            4         2              900   \n",
       "2              500          none           5         1              900   \n",
       "3              690           NaN           3         1             1315   \n",
       "4              500      Softball           4         2              760   \n",
       "5              345         None.           1         2             1315   \n",
       "6              690        soccer           4         1             1315   \n",
       "7              500          none           4         2             1315   \n",
       "8              345          none           3         2              760   \n",
       "9              345  field hockey           5         1              900   \n",
       "\n",
       "                     weight  \n",
       "0                       187  \n",
       "1                       155  \n",
       "2  I'm not answering this.   \n",
       "3             Not sure, 240  \n",
       "4                       190  \n",
       "5                       190  \n",
       "6                       180  \n",
       "7                       137  \n",
       "8                       180  \n",
       "9                       125  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Food choices data set into a variable (e.g., df_food).\n",
    "\n",
    "food_data_set_path = 'data/food_coded.csv'\n",
    "\n",
    "df_food = pd.read_csv(food_data_set_path)\n",
    "df_food.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count by hand. (lol kidding)\n",
    "a=df_food.__len__()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPA                  object\n",
       "Gender                int64\n",
       "breakfast             int64\n",
       "calories_chicken      int64\n",
       "calories_day        float64\n",
       "                     ...   \n",
       "type_sports          object\n",
       "veggies_day           int64\n",
       "vitamins              int64\n",
       "waffle_calories       int64\n",
       "weight               object\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "df_food.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Perhaps weâ€™d like to know more another day, but the team is really interested in just the relationship between calories (`calories_day`) and weight. â€¦and maybe gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you remove the other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>weight</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Not sure, 240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  calories_day                    weight  Gender\n",
       "0      0           NaN                       187       2\n",
       "1      1           3.0                       155       1\n",
       "2      2           4.0  I'm not answering this.        1\n",
       "3      3           3.0             Not sure, 240       1\n",
       "4      4           2.0                       190       1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove â€˜em.\n",
    "new_data=['calories_day', 'weight', 'Gender']\n",
    "df_filter=df_food[new_data]\n",
    "df_filter.insert(0,'Index',df_filter.index)\n",
    "#df_filter=df_filter.drop(df_filter.columns[-4], axis=1)\n",
    "df_filter.head()\n",
    "#Tried my best to name the first column as Index but everytime it creates a copy and name it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `NaN`s? How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count â€˜em.\n",
    "df_food.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta remove those `NaN`sâ€•the entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chocolate, ice cream, french fries, pretzels</td>\n",
       "      <td>stress, boredom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>690</td>\n",
       "      <td>soccer</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ice cream, cheeseburgers, chips.</td>\n",
       "      <td>I eat comfort food when im stressed out from s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>725.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mac and cheese, chocolate, and pasta</td>\n",
       "      <td>Stress, anger and sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>580.0</td>\n",
       "      <td>345</td>\n",
       "      <td>field hockey</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pasta, grandma homemade chocolate cake anythin...</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>940.0</td>\n",
       "      <td>345</td>\n",
       "      <td>soccer</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.904</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, pasta, soup, chips, popcorn</td>\n",
       "      <td>sadness, stress, cold weather</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Running</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cookies, popcorn, and chips</td>\n",
       "      <td>Sadness, boredom, late night snack</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Soccer and basketball</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>575</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>ice cream, cake, chocolate</td>\n",
       "      <td>stress,  boredom, special occasions</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>850</td>\n",
       "      <td>intramural volleyball</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "1   3.654       1          1               610           3.0           420.0   \n",
       "2     3.3       1          1               720           4.0           420.0   \n",
       "4     3.5       1          1               720           2.0           420.0   \n",
       "6     3.8       2          1               610           3.0           420.0   \n",
       "7     3.3       1          1               720           3.0           420.0   \n",
       "9     3.3       1          1               430           3.0           315.0   \n",
       "10    3.5       1          1               610           3.0           980.0   \n",
       "11  3.904       1          1               720           4.0           420.0   \n",
       "12    3.4       2          1               430           3.0           420.0   \n",
       "13    3.6       1          1               610           3.0           420.0   \n",
       "\n",
       "    coffee                                       comfort_food  \\\n",
       "1        2                        chocolate, chips, ice cream   \n",
       "2        2                    frozen yogurt, pizza, fast food   \n",
       "4        2                       Ice cream, chocolate, chips    \n",
       "6        2       Chocolate, ice cream, french fries, pretzels   \n",
       "7        1                   Ice cream, cheeseburgers, chips.   \n",
       "9        2              Mac and cheese, chocolate, and pasta    \n",
       "10       2  Pasta, grandma homemade chocolate cake anythin...   \n",
       "11       2             chocolate, pasta, soup, chips, popcorn   \n",
       "12       2                        Cookies, popcorn, and chips   \n",
       "13       2                         ice cream, cake, chocolate   \n",
       "\n",
       "                                 comfort_food_reasons  \\\n",
       "1                                Stress, bored, anger   \n",
       "2                                     stress, sadness   \n",
       "4                          Stress, boredom, cravings    \n",
       "6                                     stress, boredom   \n",
       "7   I eat comfort food when im stressed out from s...   \n",
       "9                          Stress, anger and sadness    \n",
       "10                                           Boredom    \n",
       "11                      sadness, stress, cold weather   \n",
       "12                Sadness, boredom, late night snack    \n",
       "13                stress,  boredom, special occasions   \n",
       "\n",
       "    comfort_food_reasons_coded  ...  soup  sports  thai_food  \\\n",
       "1                          1.0  ...   1.0     1.0          2   \n",
       "2                          1.0  ...   1.0     2.0          5   \n",
       "4                          1.0  ...   1.0     1.0          4   \n",
       "6                          1.0  ...   1.0     1.0          5   \n",
       "7                          1.0  ...   1.0     2.0          1   \n",
       "9                          1.0  ...   1.0     1.0          4   \n",
       "10                         2.0  ...   1.0     1.0          2   \n",
       "11                         3.0  ...   1.0     1.0          5   \n",
       "12                         3.0  ...   2.0     1.0          3   \n",
       "13                         1.0  ...   1.0     1.0          5   \n",
       "\n",
       "   tortilla_calories  turkey_calories             type_sports veggies_day  \\\n",
       "1              725.0              690             Basketball            4   \n",
       "2             1165.0              500                    none           5   \n",
       "4              940.0              500                Softball           4   \n",
       "6              940.0              690                  soccer           4   \n",
       "7              725.0              500                    none           4   \n",
       "9              580.0              345            field hockey           5   \n",
       "10             940.0              345                  soccer           5   \n",
       "11             940.0              500                 Running           5   \n",
       "12             940.0              500  Soccer and basketball            3   \n",
       "13            1165.0              850   intramural volleyball           5   \n",
       "\n",
       "    vitamins  waffle_calories                    weight  \n",
       "1          2              900                       155  \n",
       "2          1              900  I'm not answering this.   \n",
       "4          2              760                       190  \n",
       "6          1             1315                       180  \n",
       "7          2             1315                       137  \n",
       "9          1              900                       125  \n",
       "10         2              900                       116  \n",
       "11         1              900                       110  \n",
       "12         2              575                       264  \n",
       "13         2             1315                       123  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop â€˜em.\n",
    "df_filtered = df_food.dropna()\n",
    "df_filtered.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the weird non-numeric values in the column obviously meant for numeric data?\n",
    "\n",
    "Notice the data type of that column from when you got the types of all the columns?\n",
    "\n",
    "If only we could convert the column to a numeric type and drop the rows with invalid values. ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chocolate, ice cream, french fries, pretzels</td>\n",
       "      <td>stress, boredom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>690</td>\n",
       "      <td>soccer</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ice cream, cheeseburgers, chips.</td>\n",
       "      <td>I eat comfort food when im stressed out from s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>725.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mac and cheese, chocolate, and pasta</td>\n",
       "      <td>Stress, anger and sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>580.0</td>\n",
       "      <td>345</td>\n",
       "      <td>field hockey</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pasta, grandma homemade chocolate cake anythin...</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>940.0</td>\n",
       "      <td>345</td>\n",
       "      <td>soccer</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.904</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, pasta, soup, chips, popcorn</td>\n",
       "      <td>sadness, stress, cold weather</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Running</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cookies, popcorn, and chips</td>\n",
       "      <td>Sadness, boredom, late night snack</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Soccer and basketball</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>575</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>ice cream, cake, chocolate</td>\n",
       "      <td>stress,  boredom, special occasions</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>850</td>\n",
       "      <td>intramural volleyball</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza, fruit, spaghetti, chicken and Potatoes</td>\n",
       "      <td>Friends, environment and boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Hockey</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "0  3.654       1          1               610           3.0           420.0   \n",
       "1    3.5       1          1               720           2.0           420.0   \n",
       "2    3.8       2          1               610           3.0           420.0   \n",
       "3    3.3       1          1               720           3.0           420.0   \n",
       "4    3.3       1          1               430           3.0           315.0   \n",
       "5    3.5       1          1               610           3.0           980.0   \n",
       "6  3.904       1          1               720           4.0           420.0   \n",
       "7    3.4       2          1               430           3.0           420.0   \n",
       "8    3.6       1          1               610           3.0           420.0   \n",
       "9    3.1       2          1               610           3.0           420.0   \n",
       "\n",
       "   coffee                                       comfort_food  \\\n",
       "0       2                        chocolate, chips, ice cream   \n",
       "1       2                       Ice cream, chocolate, chips    \n",
       "2       2       Chocolate, ice cream, french fries, pretzels   \n",
       "3       1                   Ice cream, cheeseburgers, chips.   \n",
       "4       2              Mac and cheese, chocolate, and pasta    \n",
       "5       2  Pasta, grandma homemade chocolate cake anythin...   \n",
       "6       2             chocolate, pasta, soup, chips, popcorn   \n",
       "7       2                        Cookies, popcorn, and chips   \n",
       "8       2                         ice cream, cake, chocolate   \n",
       "9       2    Pizza, fruit, spaghetti, chicken and Potatoes     \n",
       "\n",
       "                                comfort_food_reasons  \\\n",
       "0                               Stress, bored, anger   \n",
       "1                         Stress, boredom, cravings    \n",
       "2                                    stress, boredom   \n",
       "3  I eat comfort food when im stressed out from s...   \n",
       "4                         Stress, anger and sadness    \n",
       "5                                           Boredom    \n",
       "6                      sadness, stress, cold weather   \n",
       "7                Sadness, boredom, late night snack    \n",
       "8                stress,  boredom, special occasions   \n",
       "9                   Friends, environment and boredom   \n",
       "\n",
       "   comfort_food_reasons_coded  ...  soup  sports  thai_food tortilla_calories  \\\n",
       "0                         1.0  ...   1.0     1.0          2             725.0   \n",
       "1                         1.0  ...   1.0     1.0          4             940.0   \n",
       "2                         1.0  ...   1.0     1.0          5             940.0   \n",
       "3                         1.0  ...   1.0     2.0          1             725.0   \n",
       "4                         1.0  ...   1.0     1.0          4             580.0   \n",
       "5                         2.0  ...   1.0     1.0          2             940.0   \n",
       "6                         3.0  ...   1.0     1.0          5             940.0   \n",
       "7                         3.0  ...   2.0     1.0          3             940.0   \n",
       "8                         1.0  ...   1.0     1.0          5            1165.0   \n",
       "9                         2.0  ...   1.0     1.0          4             940.0   \n",
       "\n",
       "   turkey_calories             type_sports veggies_day  vitamins  \\\n",
       "0              690             Basketball            4         2   \n",
       "1              500                Softball           4         2   \n",
       "2              690                  soccer           4         1   \n",
       "3              500                    none           4         2   \n",
       "4              345            field hockey           5         1   \n",
       "5              345                  soccer           5         2   \n",
       "6              500                 Running           5         1   \n",
       "7              500  Soccer and basketball            3         2   \n",
       "8              850   intramural volleyball           5         2   \n",
       "9              500                  Hockey           5         1   \n",
       "\n",
       "   waffle_calories  weight  \n",
       "0              900   155.0  \n",
       "1              760   190.0  \n",
       "2             1315   180.0  \n",
       "3             1315   137.0  \n",
       "4              900   125.0  \n",
       "5              900   116.0  \n",
       "6              900   110.0  \n",
       "7              575   264.0  \n",
       "8             1315   123.0  \n",
       "9              900   185.0  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix that.\n",
    "df_food['weight']=pd.to_numeric(df_food['weight'], errors='coerce')\n",
    "df_mask_numeric=df_food.dropna()\n",
    "df_mask_numeric.head()\n",
    "df_mask_numeric=df_mask_numeric.reset_index(drop=True)\n",
    "df_mask_numeric.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data seems reasonably clean for our purposes! ðŸ˜\n",
    "\n",
    "Letâ€™s save it somewhere to be shipped off to another teammate. ðŸ’¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savey save!\n",
    "save_as='Final_csv'\n",
    "df_mask_numeric.to_csv(save_as, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chocolate, ice cream, french fries, pretzels</td>\n",
       "      <td>stress, boredom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>690</td>\n",
       "      <td>soccer</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ice cream, cheeseburgers, chips.</td>\n",
       "      <td>I eat comfort food when im stressed out from s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>725.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mac and cheese, chocolate, and pasta</td>\n",
       "      <td>Stress, anger and sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>580.0</td>\n",
       "      <td>345</td>\n",
       "      <td>field hockey</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "0  3.654       1          1               610           3.0           420.0   \n",
       "1    3.5       1          1               720           2.0           420.0   \n",
       "2    3.8       2          1               610           3.0           420.0   \n",
       "3    3.3       1          1               720           3.0           420.0   \n",
       "4    3.3       1          1               430           3.0           315.0   \n",
       "\n",
       "   coffee                                  comfort_food  \\\n",
       "0       2                   chocolate, chips, ice cream   \n",
       "1       2                  Ice cream, chocolate, chips    \n",
       "2       2  Chocolate, ice cream, french fries, pretzels   \n",
       "3       1              Ice cream, cheeseburgers, chips.   \n",
       "4       2         Mac and cheese, chocolate, and pasta    \n",
       "\n",
       "                                comfort_food_reasons  \\\n",
       "0                               Stress, bored, anger   \n",
       "1                         Stress, boredom, cravings    \n",
       "2                                    stress, boredom   \n",
       "3  I eat comfort food when im stressed out from s...   \n",
       "4                         Stress, anger and sadness    \n",
       "\n",
       "   comfort_food_reasons_coded  ...  soup  sports  thai_food tortilla_calories  \\\n",
       "0                         1.0  ...   1.0     1.0          2             725.0   \n",
       "1                         1.0  ...   1.0     1.0          4             940.0   \n",
       "2                         1.0  ...   1.0     1.0          5             940.0   \n",
       "3                         1.0  ...   1.0     2.0          1             725.0   \n",
       "4                         1.0  ...   1.0     1.0          4             580.0   \n",
       "\n",
       "   turkey_calories   type_sports veggies_day  vitamins  waffle_calories  \\\n",
       "0              690   Basketball            4         2              900   \n",
       "1              500      Softball           4         2              760   \n",
       "2              690        soccer           4         1             1315   \n",
       "3              500          none           4         2             1315   \n",
       "4              345  field hockey           5         1              900   \n",
       "\n",
       "   weight  \n",
       "0   155.0  \n",
       "1   190.0  \n",
       "2   180.0  \n",
       "3   137.0  \n",
       "4   125.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex=pd.read_csv('Final_csv')\n",
    "ex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a Manager Salary Survey 2021 (Responses) Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>How old are you?</th>\n",
       "      <th>What industry do you work in?</th>\n",
       "      <th>Job title</th>\n",
       "      <th>If your job title needs additional context, please clarify here:</th>\n",
       "      <th>What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)</th>\n",
       "      <th>How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.</th>\n",
       "      <th>Please indicate the currency</th>\n",
       "      <th>If \"Other,\" please indicate the currency here:</th>\n",
       "      <th>If your income needs additional context, please provide it here:</th>\n",
       "      <th>What country do you work in?</th>\n",
       "      <th>If you're in the U.S., what state do you work in?</th>\n",
       "      <th>What city do you work in?</th>\n",
       "      <th>How many years of professional work experience do you have overall?</th>\n",
       "      <th>How many years of professional work experience do you have in your field?</th>\n",
       "      <th>What is your highest level of education completed?</th>\n",
       "      <th>What is your gender?</th>\n",
       "      <th>What is your race? (Choose all that apply.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp How old are you?  What industry do you work in?  \\\n",
       "0  4/27/2021 11:02:10            25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22            25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38            25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41            25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42            25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                  Job title  \\\n",
       "0        Research and Instruction Librarian   \n",
       "1  Change & Internal Communications Manager   \n",
       "2                      Marketing Specialist   \n",
       "3                           Program Manager   \n",
       "4                        Accounting Manager   \n",
       "\n",
       "  If your job title needs additional context, please clarify here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  \\\n",
       "0                                             55,000                                                                                                                                                                                     \n",
       "1                                             54,600                                                                                                                                                                                     \n",
       "2                                             34,000                                                                                                                                                                                     \n",
       "3                                             62,000                                                                                                                                                                                     \n",
       "4                                             60,000                                                                                                                                                                                     \n",
       "\n",
       "   How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.  \\\n",
       "0                                                0.0                                                                                                                                                \n",
       "1                                             4000.0                                                                                                                                                \n",
       "2                                                NaN                                                                                                                                                \n",
       "3                                             3000.0                                                                                                                                                \n",
       "4                                             7000.0                                                                                                                                                \n",
       "\n",
       "  Please indicate the currency  \\\n",
       "0                          USD   \n",
       "1                          GBP   \n",
       "2                          USD   \n",
       "3                          USD   \n",
       "4                          USD   \n",
       "\n",
       "  If \"Other,\" please indicate the currency here:   \\\n",
       "0                                             NaN   \n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "\n",
       "  If your income needs additional context, please provide it here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What country do you work in?  \\\n",
       "0                United States   \n",
       "1               United Kingdom   \n",
       "2                           US   \n",
       "3                          USA   \n",
       "4                           US   \n",
       "\n",
       "  If you're in the U.S., what state do you work in? What city do you work in?  \\\n",
       "0                                     Massachusetts                    Boston   \n",
       "1                                               NaN                 Cambridge   \n",
       "2                                         Tennessee               Chattanooga   \n",
       "3                                         Wisconsin                 Milwaukee   \n",
       "4                                    South Carolina                Greenville   \n",
       "\n",
       "  How many years of professional work experience do you have overall?  \\\n",
       "0                                          5-7 years                    \n",
       "1                                       8 - 10 years                    \n",
       "2                                        2 - 4 years                    \n",
       "3                                       8 - 10 years                    \n",
       "4                                       8 - 10 years                    \n",
       "\n",
       "  How many years of professional work experience do you have in your field?  \\\n",
       "0                                          5-7 years                          \n",
       "1                                          5-7 years                          \n",
       "2                                        2 - 4 years                          \n",
       "3                                          5-7 years                          \n",
       "4                                          5-7 years                          \n",
       "\n",
       "  What is your highest level of education completed? What is your gender?  \\\n",
       "0                                    Master's degree                Woman   \n",
       "1                                     College degree           Non-binary   \n",
       "2                                     College degree                Woman   \n",
       "3                                     College degree                Woman   \n",
       "4                                     College degree                Woman   \n",
       "\n",
       "  What is your race? (Choose all that apply.)  \n",
       "0                                       White  \n",
       "1                                       White  \n",
       "2                                       White  \n",
       "3                                       White  \n",
       "4                                       White  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Ask A Manager Salary Survey 2021 (Responses) data set into a variable (e.g., df_salary).\n",
    "Manager_file=pd.read_csv('data/ask_a_manager_salary_survey_2021_(responses)-form_responses_1.tsv', sep=\"\\t\")\n",
    "Manager_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was that hard? ðŸ™ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the file to something that is better for all systems.  \n",
    "* No spaces in filename (can use '_')\n",
    "* all lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore\n",
    "\n",
    "You know the drill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28062"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count by hand. Iâ€™m dead serious.\n",
    "len(Manager_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp                                                                                                                                                                                                                                object\n",
       "How old are you?                                                                                                                                                                                                                         object\n",
       "What industry do you work in?                                                                                                                                                                                                            object\n",
       "Job title                                                                                                                                                                                                                                object\n",
       "If your job title needs additional context, please clarify here:                                                                                                                                                                         object\n",
       "What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)     object\n",
       "How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.                                          float64\n",
       "Please indicate the currency                                                                                                                                                                                                             object\n",
       "If \"Other,\" please indicate the currency here:                                                                                                                                                                                           object\n",
       "If your income needs additional context, please provide it here:                                                                                                                                                                         object\n",
       "What country do you work in?                                                                                                                                                                                                             object\n",
       "If you're in the U.S., what state do you work in?                                                                                                                                                                                        object\n",
       "What city do you work in?                                                                                                                                                                                                                object\n",
       "How many years of professional work experience do you have overall?                                                                                                                                                                      object\n",
       "How many years of professional work experience do you have in your field?                                                                                                                                                                object\n",
       "What is your highest level of education completed?                                                                                                                                                                                       object\n",
       "What is your gender?                                                                                                                                                                                                                     object\n",
       "What is your race? (Choose all that apply.)                                                                                                                                                                                              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "\n",
    "Manager_file.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ohâ€¦ Ugh! Give these columns easier names to work with first. ðŸ™„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/27/2021 11:02:46</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Scholarly Publishing Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Hanover</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4/27/2021 11:02:51</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Publishing Assistant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33,000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4/27/2021 11:03:00</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Primary/Secondary)</td>\n",
       "      <td>Librarian</td>\n",
       "      <td>High school, FT</td>\n",
       "      <td>50,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Yuma</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4/27/2021 11:03:01</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Data developer/ETL Developer</td>\n",
       "      <td>112,000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4/27/2021 11:03:02</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Senior Accountant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I work for a Charter School</td>\n",
       "      <td>United States</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Palm Coast</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Hispanic, Latino, or Spanish origin, White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4/27/2021 11:03:03</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Office Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47,500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4/27/2021 11:03:07</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Deputy Title IX Coordinator/ Assistant Directo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Scranton</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Hispanic, Latino, or Spanish origin, White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4/27/2021 11:03:09</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Manager of Information Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>Asian or Asian American, White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4/27/2021 11:03:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Law</td>\n",
       "      <td>Legal Aid Staff Attorney</td>\n",
       "      <td>non-profit law firm</td>\n",
       "      <td>52,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Saint Paul</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4/27/2021 11:03:11</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Health care</td>\n",
       "      <td>Patient care coordinator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    age                       industry  \\\n",
       "0   4/27/2021 11:02:10  25-34   Education (Higher Education)   \n",
       "1   4/27/2021 11:02:22  25-34              Computing or Tech   \n",
       "2   4/27/2021 11:02:38  25-34  Accounting, Banking & Finance   \n",
       "3   4/27/2021 11:02:41  25-34                     Nonprofits   \n",
       "4   4/27/2021 11:02:42  25-34  Accounting, Banking & Finance   \n",
       "5   4/27/2021 11:02:46  25-34   Education (Higher Education)   \n",
       "6   4/27/2021 11:02:51  25-34                     Publishing   \n",
       "7   4/27/2021 11:03:00  25-34  Education (Primary/Secondary)   \n",
       "8   4/27/2021 11:03:01  45-54              Computing or Tech   \n",
       "9   4/27/2021 11:03:02  35-44  Accounting, Banking & Finance   \n",
       "10  4/27/2021 11:03:03  25-34                     Nonprofits   \n",
       "11  4/27/2021 11:03:07  35-44   Education (Higher Education)   \n",
       "12  4/27/2021 11:03:09  35-44  Accounting, Banking & Finance   \n",
       "13  4/27/2021 11:03:10  25-34                            Law   \n",
       "14  4/27/2021 11:03:11  18-24                    Health care   \n",
       "\n",
       "                                                title  \\\n",
       "0                  Research and Instruction Librarian   \n",
       "1            Change & Internal Communications Manager   \n",
       "2                                Marketing Specialist   \n",
       "3                                     Program Manager   \n",
       "4                                  Accounting Manager   \n",
       "5                      Scholarly Publishing Librarian   \n",
       "6                                Publishing Assistant   \n",
       "7                                           Librarian   \n",
       "8                                     Systems Analyst   \n",
       "9                                   Senior Accountant   \n",
       "10                                     Office Manager   \n",
       "11  Deputy Title IX Coordinator/ Assistant Directo...   \n",
       "12                    Manager of Information Services   \n",
       "13                           Legal Aid Staff Attorney   \n",
       "14                           Patient care coordinator   \n",
       "\n",
       "                   title_context   salary  additional_compensation currency  \\\n",
       "0                            NaN   55,000                      0.0      USD   \n",
       "1                            NaN   54,600                   4000.0      GBP   \n",
       "2                            NaN   34,000                      NaN      USD   \n",
       "3                            NaN   62,000                   3000.0      USD   \n",
       "4                            NaN   60,000                   7000.0      USD   \n",
       "5                            NaN   62,000                      NaN      USD   \n",
       "6                            NaN   33,000                   2000.0      USD   \n",
       "7                High school, FT   50,000                      NaN      USD   \n",
       "8   Data developer/ETL Developer  112,000                  10000.0      USD   \n",
       "9                            NaN   45,000                      0.0      USD   \n",
       "10                           NaN   47,500                      0.0      USD   \n",
       "11                           NaN   62,000                      0.0      USD   \n",
       "12                           NaN  100,000                      0.0      USD   \n",
       "13           non-profit law firm   52,000                      0.0      USD   \n",
       "14                           NaN   32,000                      NaN      CAD   \n",
       "\n",
       "   other_currency               salary_context         country  \\\n",
       "0             NaN                          NaN   United States   \n",
       "1             NaN                          NaN  United Kingdom   \n",
       "2             NaN                          NaN              US   \n",
       "3             NaN                          NaN             USA   \n",
       "4             NaN                          NaN              US   \n",
       "5             NaN                          NaN             USA   \n",
       "6             NaN                          NaN             USA   \n",
       "7             NaN                          NaN   United States   \n",
       "8             NaN                          NaN              US   \n",
       "9             NaN  I work for a Charter School   United States   \n",
       "10            NaN                          NaN   United States   \n",
       "11            NaN                          NaN             USA   \n",
       "12            NaN                          NaN   United States   \n",
       "13            NaN                          NaN   United States   \n",
       "14            NaN                          NaN          Canada   \n",
       "\n",
       "             state         city       total_yoe       field_yoe  \\\n",
       "0    Massachusetts       Boston       5-7 years       5-7 years   \n",
       "1              NaN    Cambridge    8 - 10 years       5-7 years   \n",
       "2        Tennessee  Chattanooga     2 - 4 years     2 - 4 years   \n",
       "3        Wisconsin    Milwaukee    8 - 10 years       5-7 years   \n",
       "4   South Carolina   Greenville    8 - 10 years       5-7 years   \n",
       "5    New Hampshire      Hanover    8 - 10 years     2 - 4 years   \n",
       "6   South Carolina     Columbia     2 - 4 years     2 - 4 years   \n",
       "7          Arizona         Yuma       5-7 years       5-7 years   \n",
       "8         Missouri    St. Louis   21 - 30 years   21 - 30 years   \n",
       "9          Florida   Palm Coast   21 - 30 years   21 - 30 years   \n",
       "10             NaN   Boston, MA       5-7 years       5-7 years   \n",
       "11    Pennsylvania     Scranton   11 - 20 years       5-7 years   \n",
       "12        Michigan      Detroit   11 - 20 years   11 - 20 years   \n",
       "13       Minnesota   Saint Paul     2 - 4 years     2 - 4 years   \n",
       "14             NaN       Remote  1 year or less  1 year or less   \n",
       "\n",
       "   highest_education_completed      gender  \\\n",
       "0              Master's degree       Woman   \n",
       "1               College degree  Non-binary   \n",
       "2               College degree       Woman   \n",
       "3               College degree       Woman   \n",
       "4               College degree       Woman   \n",
       "5              Master's degree         Man   \n",
       "6               College degree       Woman   \n",
       "7              Master's degree         Man   \n",
       "8               College degree       Woman   \n",
       "9               College degree       Woman   \n",
       "10              College degree       Woman   \n",
       "11                         PhD       Woman   \n",
       "12              College degree         Man   \n",
       "13                         NaN       Woman   \n",
       "14              College degree       Woman   \n",
       "\n",
       "                                          race  \n",
       "0                                        White  \n",
       "1                                        White  \n",
       "2                                        White  \n",
       "3                                        White  \n",
       "4                                        White  \n",
       "5                                        White  \n",
       "6                                        White  \n",
       "7                                        White  \n",
       "8                                        White  \n",
       "9   Hispanic, Latino, or Spanish origin, White  \n",
       "10                                       White  \n",
       "11  Hispanic, Latino, or Spanish origin, White  \n",
       "12              Asian or Asian American, White  \n",
       "13                                       White  \n",
       "14                                       White  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename â€˜em.\n",
    "# Non-binding suggestions: timestamp, age, industry, title, title_context, salary, additional_compensation, currency, other_currency, salary_context, country, state, city, total_yoe, field_yoe, highest_education_completed\tgender, race\n",
    "new_col_names=['timestamp', 'age', 'industry', 'title', 'title_context', 'salary', 'additional_compensation', 'currency', 'other_currency', 'salary_context', 'country', 'state', 'city', 'total_yoe', 'field_yoe', 'highest_education_completed','gender', 'race']\n",
    "Manager_file.columns= new_col_names\n",
    "Manager_file.iloc[0:15]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itâ€™s a lot, and that should not have been easy. ðŸ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youâ€™re going to have a gander at the computing/tech subset first because thats *your* industry. But first, what value corresponds to that `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Computing or Tech                          4699\n",
       "Education (Higher Education)               2464\n",
       "Nonprofits                                 2419\n",
       "Health care                                1896\n",
       "Government and Public Administration       1889\n",
       "                                           ... \n",
       "Gaming (Gambling)                             1\n",
       "Regulatory Affairs- nutraceuticals            1\n",
       "Manufacturing : corporate admin support       1\n",
       "Real Estate Investment Support                1\n",
       "Wine & Spirits                                1\n",
       "Name: count, Length: 1220, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the unique industries and a count of their instances.\n",
    "industries = Manager_file['industry']\n",
    "industries.value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That value among the top 5 is what youâ€™re looking for innit? Filter out all the rows not in that industry and save it into a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/27/2021 11:02:46</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Scholarly Publishing Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Hanover</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4/27/2021 11:03:01</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Data developer/ETL Developer</td>\n",
       "      <td>112,000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    age                      industry  \\\n",
       "0  4/27/2021 11:02:10  25-34  Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22  25-34             Computing or Tech   \n",
       "3  4/27/2021 11:02:41  25-34                    Nonprofits   \n",
       "5  4/27/2021 11:02:46  25-34  Education (Higher Education)   \n",
       "8  4/27/2021 11:03:01  45-54             Computing or Tech   \n",
       "\n",
       "                                      title                 title_context  \\\n",
       "0        Research and Instruction Librarian                           NaN   \n",
       "1  Change & Internal Communications Manager                           NaN   \n",
       "3                           Program Manager                           NaN   \n",
       "5            Scholarly Publishing Librarian                           NaN   \n",
       "8                           Systems Analyst  Data developer/ETL Developer   \n",
       "\n",
       "    salary  additional_compensation currency other_currency salary_context  \\\n",
       "0   55,000                      0.0      USD            NaN            NaN   \n",
       "1   54,600                   4000.0      GBP            NaN            NaN   \n",
       "3   62,000                   3000.0      USD            NaN            NaN   \n",
       "5   62,000                      NaN      USD            NaN            NaN   \n",
       "8  112,000                  10000.0      USD            NaN            NaN   \n",
       "\n",
       "          country          state       city      total_yoe      field_yoe  \\\n",
       "0   United States  Massachusetts     Boston      5-7 years      5-7 years   \n",
       "1  United Kingdom            NaN  Cambridge   8 - 10 years      5-7 years   \n",
       "3             USA      Wisconsin  Milwaukee   8 - 10 years      5-7 years   \n",
       "5             USA  New Hampshire    Hanover   8 - 10 years    2 - 4 years   \n",
       "8              US       Missouri  St. Louis  21 - 30 years  21 - 30 years   \n",
       "\n",
       "  highest_education_completed      gender   race  \n",
       "0             Master's degree       Woman  White  \n",
       "1              College degree  Non-binary  White  \n",
       "3              College degree       Woman  White  \n",
       "5             Master's degree         Man  White  \n",
       "8              College degree       Woman  White  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtery filter. (Save it to a new variable, df_salary_tech.)\n",
    "industry_counts = Manager_file['industry'].value_counts()\n",
    "top_5_industries = industry_counts.head(5).index\n",
    "df_top_5_industries = Manager_file[Manager_file['industry'].isin(top_5_industries)]\n",
    "df_salary_tech = df_top_5_industries\n",
    "df_salary_tech.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a sanity check to make sure that the only values you kept are the one you are filtered for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Computing or Tech', 'Education (Higher Education)', 'Nonprofits',\n",
      "       'Health care', 'Government and Public Administration'],\n",
      "      dtype='object', name='industry')\n",
      "industry\n",
      "Computing or Tech                       4699\n",
      "Education (Higher Education)            2464\n",
      "Nonprofits                              2419\n",
      "Health care                             1896\n",
      "Government and Public Administration    1889\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check \n",
    "print(top_5_industries)\n",
    "print(df_salary_tech['industry'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very interested in salary figures. But how many dollars ðŸ’µ is a euro ðŸ’¶ or a pound ðŸ’·? That sounds like a problem for another day. ðŸ« \n",
    "\n",
    "For now, letâ€™s just look at U.S. dollars (`'USD'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:46</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Scholarly Publishing Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Hanover</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:03:01</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Data developer/ETL Developer</td>\n",
       "      <td>112,000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:03:03</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Office Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47,500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    age                      industry  \\\n",
       "0  4/27/2021 11:02:10  25-34  Education (Higher Education)   \n",
       "1  4/27/2021 11:02:41  25-34                    Nonprofits   \n",
       "2  4/27/2021 11:02:46  25-34  Education (Higher Education)   \n",
       "3  4/27/2021 11:03:01  45-54             Computing or Tech   \n",
       "4  4/27/2021 11:03:03  25-34                    Nonprofits   \n",
       "\n",
       "                                title                 title_context   salary  \\\n",
       "0  Research and Instruction Librarian                           NaN   55,000   \n",
       "1                     Program Manager                           NaN   62,000   \n",
       "2      Scholarly Publishing Librarian                           NaN   62,000   \n",
       "3                     Systems Analyst  Data developer/ETL Developer  112,000   \n",
       "4                      Office Manager                           NaN   47,500   \n",
       "\n",
       "   additional_compensation currency other_currency salary_context  \\\n",
       "0                      0.0      USD            NaN            NaN   \n",
       "1                   3000.0      USD            NaN            NaN   \n",
       "2                      NaN      USD            NaN            NaN   \n",
       "3                  10000.0      USD            NaN            NaN   \n",
       "4                      0.0      USD            NaN            NaN   \n",
       "\n",
       "         country          state        city      total_yoe      field_yoe  \\\n",
       "0  United States  Massachusetts      Boston      5-7 years      5-7 years   \n",
       "1            USA      Wisconsin   Milwaukee   8 - 10 years      5-7 years   \n",
       "2            USA  New Hampshire     Hanover   8 - 10 years    2 - 4 years   \n",
       "3             US       Missouri   St. Louis  21 - 30 years  21 - 30 years   \n",
       "4  United States            NaN  Boston, MA      5-7 years      5-7 years   \n",
       "\n",
       "  highest_education_completed gender   race  \n",
       "0             Master's degree  Woman  White  \n",
       "1              College degree  Woman  White  \n",
       "2             Master's degree    Man  White  \n",
       "3              College degree  Woman  White  \n",
       "4              College degree  Woman  White  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtery filter for just the jobs that pay in USD!\n",
    "filtered_salary= df_salary_tech[df_top_5_industries['currency']=='USD']\n",
    "filtered_salary.head().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want know is how each U.S. city pays in tech. What value in `country` represents the United States of America?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "California                          512\n",
       "New York                            356\n",
       "Massachusetts                       313\n",
       "Illinois                            240\n",
       "Texas                               233\n",
       "                                   ... \n",
       "California, New Jersey                1\n",
       "Louisiana, Washington                 1\n",
       "District of Columbia, Washington      1\n",
       "California, Colorado                  1\n",
       "California, Maryland                  1\n",
       "Name: count, Length: 66, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We did filter for USD, so if we do a count of each unique country in descending count order, the relevant value(s) should show up at the top.\n",
    "country_count= filtered_salary['country'].value_counts()\n",
    "us_cities= filtered_salary[filtered_salary['country']==country_count.index[0]]\n",
    "city_pay= us_cities['state'].value_counts()\n",
    "city_pay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Well, we canâ€™t get our answers with what we currently have, so youâ€™ll have to make some changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s not worry about anything below the first 5 values for now. Convert the top 5 to a single canonical valueâ€•say, `'US'`, which is nice and short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6412\\192570661.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  us_cities['country'] = us_cities['country'].replace(['United States','USA'], 'US')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:03:03</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Office Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47,500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:03:23</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Assistant Director of Academic Advising</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Boca Raton</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:03:24</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Coordinator &amp; Assistant Editor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:03:29</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Government and Public Administration</td>\n",
       "      <td>Researcher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96,000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Dayton</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Asian or Asian American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    age                              industry  \\\n",
       "0  4/27/2021 11:02:10  25-34          Education (Higher Education)   \n",
       "1  4/27/2021 11:03:03  25-34                            Nonprofits   \n",
       "2  4/27/2021 11:03:23  35-44          Education (Higher Education)   \n",
       "3  4/27/2021 11:03:24  35-44                            Nonprofits   \n",
       "4  4/27/2021 11:03:29  35-44  Government and Public Administration   \n",
       "\n",
       "                                     title title_context  salary  \\\n",
       "0       Research and Instruction Librarian           NaN  55,000   \n",
       "1                           Office Manager           NaN  47,500   \n",
       "2  Assistant Director of Academic Advising           NaN  54,000   \n",
       "3  Program Coordinator & Assistant Editor            NaN  50,000   \n",
       "4                               Researcher           NaN  96,000   \n",
       "\n",
       "   additional_compensation currency other_currency salary_context country  \\\n",
       "0                      0.0      USD            NaN            NaN      US   \n",
       "1                      0.0      USD            NaN            NaN      US   \n",
       "2                      NaN      USD            NaN            NaN      US   \n",
       "3                      NaN      USD            NaN            NaN      US   \n",
       "4                   1000.0      USD            NaN            NaN      US   \n",
       "\n",
       "           state        city      total_yoe      field_yoe  \\\n",
       "0  Massachusetts      Boston      5-7 years      5-7 years   \n",
       "1            NaN  Boston, MA      5-7 years      5-7 years   \n",
       "2        Florida  Boca Raton  11 - 20 years  11 - 20 years   \n",
       "3            NaN     Atlanta      5-7 years    2 - 4 years   \n",
       "4           Ohio      Dayton   8 - 10 years    2 - 4 years   \n",
       "\n",
       "  highest_education_completed gender                     race  \n",
       "0             Master's degree  Woman                    White  \n",
       "1              College degree  Woman                    White  \n",
       "2             Master's degree  Woman                    White  \n",
       "3                         PhD  Woman                    White  \n",
       "4                         PhD  Woman  Asian or Asian American  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace them all with 'US'.\n",
    "us_cities['country'] = us_cities['country'].replace(['United States','USA'], 'US')\n",
    "us_cities.head().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the count of each unique country again now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US']\n"
     ]
    }
   ],
   "source": [
    "# Count again.\n",
    "us_cities['country'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['US']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6412\\1726776197.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  us_cities['country'] = us_cities['country'].replace(variants_to_replace)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6412\\1726776197.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  us_cities['country'] = us_cities['country'].apply(lambda x: 'US' if x not in ['US'] else x)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6412\\1726776197.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  us_cities['country'].fillna('US', inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6412\\1726776197.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  us_cities['country'].fillna('US', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# BONUS CREDIT: resolve [most of] those anomalous cases too without exhaustively taking every variant literally into account.\n",
    "# List of known variants that should be standardized to 'US'\n",
    "variants_to_replace = {\n",
    "    'USA': 'US',\n",
    "    'United States of America': 'US',\n",
    "    'U.S.': 'US',\n",
    "    'U.S.A.': 'US',\n",
    "    'United States': 'US'\n",
    "}\n",
    "\n",
    "# Replace known variants with 'US'\n",
    "us_cities['country'] = us_cities['country'].replace(variants_to_replace)\n",
    "# Replace any non-'US' value with 'US'\n",
    "us_cities['country'] = us_cities['country'].apply(lambda x: 'US' if x not in ['US'] else x)\n",
    "# Check for missing values\n",
    "print(us_cities['country'].isnull().sum())\n",
    "# Fill missing values with 'US'\n",
    "us_cities['country'].fillna('US', inplace=True)\n",
    "# Print unique values again to confirm\n",
    "print(us_cities['country'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "US    4318\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# BONUS CREDIT: if youâ€™ve resolved it, letâ€™s see how well you did by counting the number of instances of each unique value.\n",
    "us_cities['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itâ€™s looking good so far. Letâ€™s find out the minimum, mean, and maximum (in that order) salary by state, sorted by the mean in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1942\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6548\u001b[0m ):\n\u001b[1;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12422\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  12379\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6456\u001b[0m     )\n\u001b[1;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[1;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1700\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[1;32m-> 1701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert string '37,79682,00075,00029,07828,00077,00075,00070,50052,50050,00061,000120,00078,00077651' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Find the minimum, mean, and maximum salary in USD by U.S. state.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m us_cities\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:257\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m    256\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m--> 257\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_multiple_funcs(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:362\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[0;32m    361\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[1;32m--> 362\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:249\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, func)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2446\u001b[0m         grouped_mean,\n\u001b[0;32m   2447\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2448\u001b[0m         engine_kwargs,\n\u001b[0;32m   2449\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2450\u001b[0m     )\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:367\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[0;32m    366\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[1;32m--> 367\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(arr)\n\u001b[0;32m    368\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[0;32m    370\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1995\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1944\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[1;32m-> 1946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m   1949\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# Find the minimum, mean, and maximum salary in USD by U.S. state.\n",
    "us_cities.groupby('state')['salary'].agg(['min','mean', 'max']).sort_values(by='mean', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, pooh! We forgot that `salary` isnâ€™t numeric. Something wrong must be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6412\\4225415215.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  us_cities['salary'] = pd.to_numeric(us_cities['salary'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Fix it.\n",
    "us_cities['salary'] = pd.to_numeric(us_cities['salary'], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California, Oregon</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California, Colorado</th>\n",
       "      <td>176000.0</td>\n",
       "      <td>176000.000000</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>54600.0</td>\n",
       "      <td>137300.000000</td>\n",
       "      <td>220000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.0</td>\n",
       "      <td>129744.852113</td>\n",
       "      <td>350000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>117179.532258</td>\n",
       "      <td>1250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts, Rhode Island</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio, Washington</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas, Virginia</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah, Vermont</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  min           mean        max\n",
       "state                                                          \n",
       "California, Oregon           200000.0  200000.000000   200000.0\n",
       "California, Colorado         176000.0  176000.000000   176000.0\n",
       "Delaware                      54600.0  137300.000000   220000.0\n",
       "California                        0.0  129744.852113   350000.0\n",
       "District of Columbia          45000.0  117179.532258  1250000.0\n",
       "...                               ...            ...        ...\n",
       "Massachusetts, Rhode Island       NaN            NaN        NaN\n",
       "North Dakota                      NaN            NaN        NaN\n",
       "Ohio, Washington                  NaN            NaN        NaN\n",
       "Texas, Virginia                   NaN            NaN        NaN\n",
       "Utah, Vermont                     NaN            NaN        NaN\n",
       "\n",
       "[66 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try it again. Yeah!\n",
    "\n",
    "us_cities.groupby('state')['salary'].agg(['min','mean', 'max']).sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did the trick! Now letâ€™s narrow this to data 2021 and 2022 just because (lel). *(Hint: that timestamp column may not be a temporal type right now.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "                                     min      mean       max\n",
      "state                                                       \n",
      "California, Colorado            176000.0  176000.0  176000.0\n",
      "Louisiana, Washington           117000.0  117000.0  117000.0\n",
      "California, Oregon                   0.0  100000.0  200000.0\n",
      "California, Maryland             81500.0   81500.0   81500.0\n",
      "Hawaii                               0.0   43615.0  142000.0\n",
      "...                                  ...       ...       ...\n",
      "District of Columbia, Virginia       0.0       0.0       0.0\n",
      "District of Columbia, Maryland       0.0       0.0       0.0\n",
      "Colorado, Illinois                   0.0       0.0       0.0\n",
      "California, New Jersey               0.0       0.0       0.0\n",
      "Massachusetts, Pennsylvania          0.0       0.0       0.0\n",
      "\n",
      "[66 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6412\\883650844.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  us_cities['timestamp'] = pd.to_datetime(us_cities['timestamp'], errors='coerce')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6412\\883650844.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  filtered_data['salary'].fillna(0, inplace=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6412\\883650844.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['salary'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "us_cities['timestamp'] = pd.to_datetime(us_cities['timestamp'], errors='coerce')\n",
    "\n",
    "filtered_data = us_cities[us_cities['timestamp'].dt.year.isin([2021, 2022, 2023])]\n",
    "\n",
    "print(filtered_data['salary'].dtype)\n",
    "\n",
    "if filtered_data['salary'].dtype == 'object':\n",
    "    filtered_data['salary'] = pd.to_numeric(filtered_data['salary'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "filtered_data['salary'].fillna(0, inplace=True)\n",
    "salary_stats_filtered = filtered_data.groupby('state')['salary'].agg(['min', 'mean', 'max'])\n",
    "\n",
    "salary_stats_sorted_filtered = salary_stats_filtered.sort_values(by='mean', ascending=False)\n",
    "\n",
    "print(salary_stats_sorted_filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Clearly, we do not have enough data to produce useful figures for the level of specificity youâ€™ve now reached. What do you notice about Delaware and West Virginia?\n",
    "\n",
    "Letâ€™s back out a bit and return to `df_salary` (which was the loaded data with renamed columns but *sans* filtering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #0\n",
    "\n",
    "Apply the same steps as before to `df_salary`, but do not filter for any specific industry. Do perform the other data cleaning stuff, and get to a point where you can generate the minimum, mean, and maximum by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #1\n",
    "\n",
    "This time, format the table output nicely (*$12,345.00*) without modifying the values in the `DataFrame`. That is, `df_salary` should be identical before versus after running your code.\n",
    "\n",
    "(*Hint: if you run into an error about `jinja2` perhaps you need to `pip install` something.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #2\n",
    "\n",
    "Filter out the non-single-states (e.g., `'California, Colorado'`) in the most elegant way possible (i.e., *not* by blacklisting all the bad values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>0.0</td>\n",
       "      <td>43615.000000</td>\n",
       "      <td>142000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>0.0</td>\n",
       "      <td>39228.571429</td>\n",
       "      <td>220000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35983.923828</td>\n",
       "      <td>350000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31940.829545</td>\n",
       "      <td>645000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31925.358407</td>\n",
       "      <td>1250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31848.039216</td>\n",
       "      <td>230000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31227.963483</td>\n",
       "      <td>590000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29705.882353</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29426.673759</td>\n",
       "      <td>220000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29270.105263</td>\n",
       "      <td>145000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28453.500000</td>\n",
       "      <td>63686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27826.346154</td>\n",
       "      <td>170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>0.0</td>\n",
       "      <td>26510.141593</td>\n",
       "      <td>165000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25728.466454</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25676.720430</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25208.517007</td>\n",
       "      <td>230000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24313.261364</td>\n",
       "      <td>235000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24170.465217</td>\n",
       "      <td>220000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23958.603960</td>\n",
       "      <td>170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23693.005556</td>\n",
       "      <td>237000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23198.750000</td>\n",
       "      <td>230000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22044.938776</td>\n",
       "      <td>220000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21715.237288</td>\n",
       "      <td>125500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21499.981818</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20947.777778</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20805.227468</td>\n",
       "      <td>170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20098.071429</td>\n",
       "      <td>340000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20079.313725</td>\n",
       "      <td>142000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19530.000000</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19493.238095</td>\n",
       "      <td>107500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19061.185185</td>\n",
       "      <td>164500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18865.454545</td>\n",
       "      <td>77000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18433.333333</td>\n",
       "      <td>82000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18226.600000</td>\n",
       "      <td>147000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17044.117647</td>\n",
       "      <td>142000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16864.716418</td>\n",
       "      <td>143520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16839.137615</td>\n",
       "      <td>179000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16013.333333</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15338.095238</td>\n",
       "      <td>142000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14639.939850</td>\n",
       "      <td>158000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14621.121212</td>\n",
       "      <td>125000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12726.315789</td>\n",
       "      <td>76800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11250.000000</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10704.545455</td>\n",
       "      <td>76000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8875.000000</td>\n",
       "      <td>71000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6885.333333</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5727.272727</td>\n",
       "      <td>63000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2807.823529</td>\n",
       "      <td>47733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      min          mean        max\n",
       "state                                             \n",
       "Hawaii                0.0  43615.000000   142000.0\n",
       "Delaware              0.0  39228.571429   220000.0\n",
       "California            0.0  35983.923828   350000.0\n",
       "Florida               0.0  31940.829545   645000.0\n",
       "District of Columbia  0.0  31925.358407  1250000.0\n",
       "New Jersey            0.0  31848.039216   230000.0\n",
       "New York              0.0  31227.963483   590000.0\n",
       "Maine                 0.0  29705.882353   110000.0\n",
       "Virginia              0.0  29426.673759   220000.0\n",
       "Montana               0.0  29270.105263   145000.0\n",
       "Wyoming               0.0  28453.500000    63686.0\n",
       "Idaho                 0.0  27826.346154   170000.0\n",
       "Colorado              0.0  26510.141593   165000.0\n",
       "Massachusetts         0.0  25728.466454   400000.0\n",
       "Georgia               0.0  25676.720430   270000.0\n",
       "Oregon                0.0  25208.517007   230000.0\n",
       "Michigan              0.0  24313.261364   235000.0\n",
       "Washington            0.0  24170.465217   220000.0\n",
       "Maryland              0.0  23958.603960   170000.0\n",
       "Pennsylvania          0.0  23693.005556   237000.0\n",
       "Connecticut           0.0  23198.750000   230000.0\n",
       "Tennessee             0.0  22044.938776   220000.0\n",
       "North Carolina        0.0  21715.237288   125500.0\n",
       "Missouri              0.0  21499.981818   200000.0\n",
       "Utah                  0.0  20947.777778   176000.0\n",
       "Texas                 0.0  20805.227468   170000.0\n",
       "Illinois              0.0  20098.071429   340000.0\n",
       "Arizona               0.0  20079.313725   142000.0\n",
       "Vermont               0.0  19530.000000   120000.0\n",
       "Oklahoma              0.0  19493.238095   107500.0\n",
       "Kansas                0.0  19061.185185   164500.0\n",
       "Arkansas              0.0  18865.454545    77000.0\n",
       "New Mexico            0.0  18433.333333    82000.0\n",
       "Wisconsin             0.0  18226.600000   147000.0\n",
       "Iowa                  0.0  17044.117647   142000.0\n",
       "Indiana               0.0  16864.716418   143520.0\n",
       "Ohio                  0.0  16839.137615   179000.0\n",
       "Nebraska              0.0  16013.333333   140000.0\n",
       "Nevada                0.0  15338.095238   142000.0\n",
       "Minnesota             0.0  14639.939850   158000.0\n",
       "Kentucky              0.0  14621.121212   125000.0\n",
       "Louisiana             0.0  12726.315789    76800.0\n",
       "Mississippi           0.0  11250.000000    90000.0\n",
       "Rhode Island          0.0  10704.545455    76000.0\n",
       "West Virginia         0.0   8875.000000    71000.0\n",
       "New Hampshire         0.0   6885.333333    70000.0\n",
       "Alaska                0.0   5727.272727    63000.0\n",
       "South Carolina        0.0   2807.823529    47733.0\n",
       "North Dakota          0.0      0.000000        0.0\n",
       "Alabama               0.0      0.000000        0.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_clean = filtered_data.dropna(subset=['state'])\n",
    "filtered_single_states = filtered_data_clean[filtered_data_clean['state'].str.match(r'^[^,]+$', na=False)]\n",
    "\n",
    "salary_stats_filtered = filtered_single_states.groupby('state')['salary'].agg(['min', 'mean', 'max'])\n",
    "\n",
    "salary_stats_sorted_filtered = salary_stats_filtered.sort_values(by='mean', ascending=False)\n",
    "\n",
    "salary_stats_sorted_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #3\n",
    "\n",
    "Show the quantiles instead of just minimum, mean, and maximumâ€•say 0%, 5%, 25%, 50%, 75%, 95%, and 100%. Outliers may be deceiving.\n",
    "\n",
    "Sort by whatever interests youâ€•like say the *50th* percentile.\n",
    "\n",
    "And throw in a count by state too. It would be interesting to know how many data points contribute to the figures for each state. (*Hint: your nice formatting from Bonus #1 might not work this time around.* ðŸ˜œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.95</th>\n",
       "      <th>1.0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25064.0</td>\n",
       "      <td>53517.5</td>\n",
       "      <td>61652.30</td>\n",
       "      <td>63686.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16230.0</td>\n",
       "      <td>59845.0</td>\n",
       "      <td>125569.00</td>\n",
       "      <td>142000.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40500.0</td>\n",
       "      <td>115050.00</td>\n",
       "      <td>237000.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107100.00</td>\n",
       "      <td>142000.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44296.00</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>114500.00</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36450.0</td>\n",
       "      <td>80600.00</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45750.0</td>\n",
       "      <td>159750.00</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39100.0</td>\n",
       "      <td>105474.00</td>\n",
       "      <td>125500.0</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>78000.00</td>\n",
       "      <td>179000.0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>65000.00</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45380.0</td>\n",
       "      <td>126750.00</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58875.00</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50750.0</td>\n",
       "      <td>129700.00</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9546.60</td>\n",
       "      <td>47733.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103200.00</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41241.0</td>\n",
       "      <td>97257.80</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111100.00</td>\n",
       "      <td>176000.0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102750.00</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>131300.00</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151044.65</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46150.00</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112750.00</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79600.00</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31500.00</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58500.00</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>111500.00</td>\n",
       "      <td>142000.0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>71260.00</td>\n",
       "      <td>77000.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57455.5</td>\n",
       "      <td>184500.00</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>119000.00</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110400.00</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27300.0</td>\n",
       "      <td>170380.00</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53165.0</td>\n",
       "      <td>135000.00</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46175.0</td>\n",
       "      <td>145200.00</td>\n",
       "      <td>645000.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>130080.00</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52250.0</td>\n",
       "      <td>93875.00</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127360.00</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>84600.00</td>\n",
       "      <td>143520.0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117300.00</td>\n",
       "      <td>142000.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>90240.00</td>\n",
       "      <td>164500.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86000.00</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75180.00</td>\n",
       "      <td>76800.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58500.0</td>\n",
       "      <td>98000.00</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>130000.00</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140200.00</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49250.0</td>\n",
       "      <td>116658.20</td>\n",
       "      <td>235000.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112000.00</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36500.0</td>\n",
       "      <td>102500.00</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0.0  0.05  0.25      0.5     0.75       0.95        1.0  \\\n",
       "state                                                                           \n",
       "Wyoming               0.0   0.0   0.0  25064.0  53517.5   61652.30    63686.0   \n",
       "Hawaii                0.0   0.0   0.0  16230.0  59845.0  125569.00   142000.0   \n",
       "Pennsylvania          0.0   0.0   0.0      0.0  40500.0  115050.00   237000.0   \n",
       "Nevada                0.0   0.0   0.0      0.0      0.0  107100.00   142000.0   \n",
       "New Hampshire         0.0   0.0   0.0      0.0      0.0   44296.00    70000.0   \n",
       "New Jersey            0.0   0.0   0.0      0.0  57000.0  114500.00   230000.0   \n",
       "New Mexico            0.0   0.0   0.0      0.0  36450.0   80600.00    82000.0   \n",
       "New York              0.0   0.0   0.0      0.0  45750.0  159750.00   590000.0   \n",
       "North Carolina        0.0   0.0   0.0      0.0  39100.0  105474.00   125500.0   \n",
       "North Dakota          0.0   0.0   0.0      0.0      0.0       0.00        0.0   \n",
       "Ohio                  0.0   0.0   0.0      0.0  24000.0   78000.00   179000.0   \n",
       "Oklahoma              0.0   0.0   0.0      0.0  37000.0   65000.00   107500.0   \n",
       "Oregon                0.0   0.0   0.0      0.0  45380.0  126750.00   230000.0   \n",
       "Rhode Island          0.0   0.0   0.0      0.0      0.0   58875.00    76000.0   \n",
       "Montana               0.0   0.0   0.0      0.0  50750.0  129700.00   145000.0   \n",
       "South Carolina        0.0   0.0   0.0      0.0      0.0    9546.60    47733.0   \n",
       "Tennessee             0.0   0.0   0.0      0.0      0.0  103200.00   220000.0   \n",
       "Texas                 0.0   0.0   0.0      0.0  41241.0   97257.80   170000.0   \n",
       "Utah                  0.0   0.0   0.0      0.0      0.0  111100.00   176000.0   \n",
       "Vermont               0.0   0.0   0.0      0.0      0.0  102750.00   120000.0   \n",
       "Virginia              0.0   0.0   0.0      0.0  53000.0  131300.00   220000.0   \n",
       "Washington            0.0   0.0   0.0      0.0      0.0  151044.65   220000.0   \n",
       "West Virginia         0.0   0.0   0.0      0.0      0.0   46150.00    71000.0   \n",
       "Wisconsin             0.0   0.0   0.0      0.0      0.0  112750.00   147000.0   \n",
       "Nebraska              0.0   0.0   0.0      0.0      0.0   79600.00   140000.0   \n",
       "Alabama               0.0   0.0   0.0      0.0      0.0       0.00        0.0   \n",
       "Alaska                0.0   0.0   0.0      0.0      0.0   31500.00    63000.0   \n",
       "Mississippi           0.0   0.0   0.0      0.0      0.0   58500.00    90000.0   \n",
       "Arizona               0.0   0.0   0.0      0.0  17000.0  111500.00   142000.0   \n",
       "Arkansas              0.0   0.0   0.0      0.0  32500.0   71260.00    77000.0   \n",
       "California            0.0   0.0   0.0      0.0  57455.5  184500.00   350000.0   \n",
       "Colorado              0.0   0.0   0.0      0.0  58000.0  119000.00   165000.0   \n",
       "Connecticut           0.0   0.0   0.0      0.0      0.0  110400.00   230000.0   \n",
       "Delaware              0.0   0.0   0.0      0.0  27300.0  170380.00   220000.0   \n",
       "District of Columbia  0.0   0.0   0.0      0.0  53165.0  135000.00  1250000.0   \n",
       "Florida               0.0   0.0   0.0      0.0  46175.0  145200.00   645000.0   \n",
       "Georgia               0.0   0.0   0.0      0.0  30000.0  130080.00   270000.0   \n",
       "Idaho                 0.0   0.0   0.0      0.0  52250.0   93875.00   170000.0   \n",
       "Illinois              0.0   0.0   0.0      0.0      0.0  127360.00   340000.0   \n",
       "Indiana               0.0   0.0   0.0      0.0   7500.0   84600.00   143520.0   \n",
       "Iowa                  0.0   0.0   0.0      0.0      0.0  117300.00   142000.0   \n",
       "Kansas                0.0   0.0   0.0      0.0     26.0   90240.00   164500.0   \n",
       "Kentucky              0.0   0.0   0.0      0.0      0.0   86000.00   125000.0   \n",
       "Louisiana             0.0   0.0   0.0      0.0      0.0   75180.00    76800.0   \n",
       "Maine                 0.0   0.0   0.0      0.0  58500.0   98000.00   110000.0   \n",
       "Maryland              0.0   0.0   0.0      0.0  33000.0  130000.00   170000.0   \n",
       "Massachusetts         0.0   0.0   0.0      0.0      0.0  140200.00   400000.0   \n",
       "Michigan              0.0   0.0   0.0      0.0  49250.0  116658.20   235000.0   \n",
       "Minnesota             0.0   0.0   0.0      0.0      0.0  112000.00   158000.0   \n",
       "Missouri              0.0   0.0   0.0      0.0  36500.0  102500.00   200000.0   \n",
       "\n",
       "                      count  \n",
       "state                        \n",
       "Wyoming                   4  \n",
       "Hawaii                    4  \n",
       "Pennsylvania            180  \n",
       "Nevada                   21  \n",
       "New Hampshire            15  \n",
       "New Jersey               51  \n",
       "New Mexico               15  \n",
       "New York                356  \n",
       "North Carolina          118  \n",
       "North Dakota              8  \n",
       "Ohio                    109  \n",
       "Oklahoma                 21  \n",
       "Oregon                  147  \n",
       "Rhode Island             11  \n",
       "Montana                  19  \n",
       "South Carolina           17  \n",
       "Tennessee                49  \n",
       "Texas                   233  \n",
       "Utah                     54  \n",
       "Vermont                  13  \n",
       "Virginia                141  \n",
       "Washington              230  \n",
       "West Virginia             8  \n",
       "Wisconsin                90  \n",
       "Nebraska                 21  \n",
       "Alabama                  13  \n",
       "Alaska                   11  \n",
       "Mississippi               8  \n",
       "Arizona                  51  \n",
       "Arkansas                 11  \n",
       "California              512  \n",
       "Colorado                113  \n",
       "Connecticut              32  \n",
       "Delaware                  7  \n",
       "District of Columbia    226  \n",
       "Florida                  88  \n",
       "Georgia                  93  \n",
       "Idaho                    26  \n",
       "Illinois                238  \n",
       "Indiana                  67  \n",
       "Iowa                     34  \n",
       "Kansas                   27  \n",
       "Kentucky                 33  \n",
       "Louisiana                19  \n",
       "Maine                    17  \n",
       "Maryland                101  \n",
       "Massachusetts           313  \n",
       "Michigan                 88  \n",
       "Minnesota               133  \n",
       "Missouri                 55  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_clean = filtered_data.dropna(subset=['state'])\n",
    "\n",
    "filtered_single_states = filtered_data_clean[filtered_data_clean['state'].str.match(r'^[^,]+$', na=False)]\n",
    "quantiles = [0, 0.05, 0.25, 0.50, 0.75, 0.95, 1.0]\n",
    "\n",
    "salary_stats_filtered = filtered_single_states.groupby('state')['salary'].quantile(quantiles).unstack()\n",
    "salary_stats_filtered['count'] = filtered_single_states.groupby('state')['salary'].count()\n",
    "\n",
    "salary_stats_sorted_filtered = salary_stats_filtered.sort_values(by=0.50, ascending=False)\n",
    "\n",
    "salary_stats_sorted_filtered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
